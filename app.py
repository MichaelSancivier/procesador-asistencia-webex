import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import io
import re

# ====================================================================
# Funci√≥n de procesamiento del CSV de Webex
# ====================================================================
def processar_assistencia(df_input):
    """
    Processa um DataFrame de lista de presen√ßa do Webex e gera um relat√≥rio.
    """
    df = df_input.copy()  # Trabalhar com uma c√≥pia para n√£o modificar o DataFrame original
    
    # Mapeamento de colunas esperadas (com nomes exatos confirmados)
    colunas_esperadas = [
        'Nome da reuni√£o', 'Data de in√≠cio da reuni√£o', 'Data de t√©rmino da reuni√£o', 
        'Nome de exibi√ß√£o', 'Nome', 'Sobrenome', 'Fun√ß√£o', 'E-mail do convidado', 
        'Hora da entrada', 'Hora da sa√≠da', 'Dura√ß√£o da presen√ßa', 
        'Tipo de conex√£o', 'Nome da sess√£o'
    ]

    # 1. Atribuir os nomes de colunas esperados (j√° foram lidos sem cabe√ßalho)
    # A verifica√ß√£o de colunas agora √© feita pelo √≠ndice, pois a leitura √© manual
    if len(df.columns) != len(colunas_esperadas):
        st.error(f"Erro: O n√∫mero de colunas encontradas ({len(df.columns)}) n√£o corresponde ao n√∫mero de colunas esperadas ({len(colunas_esperadas)}).")
        st.info("Isso pode indicar que o arquivo tem um formato diferente ou dados corrompidos.")
        return None, None
        
    df.columns = colunas_esperadas # Atribui o cabe√ßalho correto
    
    # ===============================================================
    # --- PASSO DE DEPURA√á√ÉO: EXIBIR AS COLUNAS Lidas ---
    # ===============================================================
    st.info(f"Colunas do DataFrame (ap√≥s atribui√ß√£o manual): {list(df.columns)}")
    # ===============================================================

    # Contar registros totais e v√°lidos antes da limpeza
    total_registros_processados = len(df)
    registros_validos_antes = len(df)
    
    # 2. Remover registros com dados faltantes essenciais
    df.dropna(subset=['E-mail do convidado', 'Hora da entrada', 'Hora da sa√≠da'], inplace=True)
    registros_ignorados = registros_validos_antes - len(df)
    
    # --- CORRE√á√ÉO: CONVERTER COLUNA 'DURA√á√ÉO' PARA N√öMERO ---
    try:
        # Substituir v√≠rgulas por pontos para o pandas entender como decimal
        df['Dura√ß√£o da presen√ßa'] = df['Dura√ß√£o da presen√ßa'].astype(str).str.replace(',', '.', regex=False)
        # Converter para num√©rico, for√ßando valores inv√°lidos para NaN
        df['Dura√ß√£o da presen√ßa'] = pd.to_numeric(df['Dura√ß√£o da presen√ßa'], errors='coerce')
        # Remover linhas onde a dura√ß√£o n√£o √© um n√∫mero
        registros_validos_antes_duracao = len(df)
        df.dropna(subset=['Dura√ß√£o da presen√ßa'], inplace=True)
        registros_ignorados += registros_validos_antes_duracao - len(df)
    except Exception as e:
        st.error(f"Erro ao limpar a coluna 'Dura√ß√£o da presen√ßa'. Verifique se ela cont√©m apenas valores num√©ricos. Erro: {e}")
        return None, None
    # --------------------------------------------------------

    if df.empty:
        return None, {"total_registros_processados": total_registros_processados, 
                      "registros_ignorados": registros_ignorados, 
                      "presentes": 0, "ausentes": 0}

    try:
        # 3. Converter colunas de tempo para o formato datetime
        df['Hora da entrada'] = pd.to_datetime(df['Hora da entrada'])
        df['Hora da sa√≠da'] = pd.to_datetime(df['Hora da sa√≠da'])
        df['Data de in√≠cio da reuni√£o'] = pd.to_datetime(df['Data de in√≠cio da reuni√£o'])
        df['Data de t√©rmino da reuni√£o'] = pd.to_datetime(df['Data de t√©rmino da reuni√£o'])
    except Exception as e:
        st.error(f"Erro ao converter colunas de data/hora. Verifique o formato dos dados. Erro: {e}")
        return None, None

    # 4. Calcular a dura√ß√£o total da aula
    try:
        duracao_total_aula_min = (df['Data de t√©rmino da reuni√£o'].iloc[0] - df['Data de in√≠cio da reuni√£o'].iloc[0]).total_seconds() / 60
    except IndexError:
        st.error("Erro: O arquivo est√° vazio ou n√£o cont√©m informa√ß√µes de dura√ß√£o da reuni√£o.")
        return None, None

    if duracao_total_aula_min <= 0:
        st.error("Erro: N√£o foi poss√≠vel calcular a dura√ß√£o da aula. Verifique as datas de in√≠cio e t√©rmino da reuni√£o.")
        return None, None

    # 5. Agrupar por e-mail para consolidar os registros de cada aluno
    grupos_por_email = df.groupby('E-mail do convidado')
    
    resultados = []

    # 6. Iterar sobre cada grupo (aluno) para consolidar os dados
    for email, grupo in grupos_por_email:
        entrada_consolidada = grupo['Hora da entrada'].min()
        saida_consolidada = grupo['Hora da sa√≠da'].max()
        tempo_total_min = grupo['Dura√ß√£o da presen√ßa'].sum()
        porcentagem_tempo = (tempo_total_min / duracao_total_aula_min) * 100
        
        # 7. An√°lise por tramos (slots) de 60 minutos
        tramos_participados = 0
        total_tramos = int(duracao_total_aula_min / 60)
        if duracao_total_aula_min % 60 > 0:
            total_tramos += 1
        
        hora_inicio_aula = df['Data de in√≠cio da reuni√£o'].iloc[0]
        
        for i in range(total_tramos):
            inicio_tramo = hora_inicio_aula + timedelta(minutes=i*60)
            fim_tramo = inicio_tramo + timedelta(minutes=60)
            
            participou_do_tramo = False
            for _, registro in grupo.iterrows():
                if (registro['Hora da entrada'] < fim_tramo) and (registro['Hora da sa√≠da'] > inicio_tramo):
                    participou_do_tramo = True
                    break
            
            if participou_do_tramo:
                tramos_participados += 1

        porcentagem_tramos = (tramos_participados / total_tramos) * 100 if total_tramos > 0 else 0
        status = 'Presente' if porcentagem_tempo >= 80 and porcentagem_tramos >= 80 else 'Ausente'
        
        try:
            nome_aluno = grupo.iloc[0]['Nome'] + ' ' + grupo.iloc[0]['Sobrenome']
        except KeyError:
            nome_aluno = grupo.iloc[0]['Nome de exibi√ß√£o']
            
        resultados.append({
            'Nome': nome_aluno,
            'E-mail do convidado': email,
            'Entrada Consolidada': entrada_consolidada.strftime('%Y-%m-%d %H:%M:%S'),
            'Sa√≠da Consolidada': saida_consolidada.strftime('%Y-%m-%d %H:%M:%S'),
            'Tempo Total (min)': round(tempo_total_min, 2),
            'Porcentagem de Tempo (%)': round(porcentagem_tempo, 2),
            'Tramos Participados': tramos_participados,
            'Porcentagem de Tramos (%)': round(porcentagem_tramos, 2),
            'Status': status
        })

    # 8. Gerar o novo DataFrame
    df_final = pd.DataFrame(resultados)
    
    # 9. Gerar o resumo
    presentes = len(df_final[df_final['Status'] == 'Presente'])
    ausentes = len(df_final[df_final['Status'] == 'Ausente'])
    
    resumo = {
        "total_registros_processados": total_registros_processados,
        "registros_ignorados": registros_ignorados,
        "presentes": presentes,
        "ausentes": ausentes
    }
    
    return df_final, resumo

# ====================================================================
# Interfaz de usuario con Streamlit
# ====================================================================

st.set_page_config(page_title="Procesador de Asistencia Webex", layout="wide", page_icon="üë®‚Äçüè´")
st.title("üë®‚Äçüè´ Procesador de Asistencia para Moodle")
st.markdown("Suba su archivo CSV de la lista de presencia de Webex para generar un informe listo para importar en Moodle.")
st.divider()

uploaded_file = st.file_uploader("üì• Cargue el archivo CSV aqu√≠", type=["csv"])

if uploaded_file is not None:
    try:
        df_input = None
        
        # Leemos el contenido del archivo como texto para el an√°lisis manual
        file_content_bytes = uploaded_file.getvalue()
        decoded_content = None
        for encoding in ['utf-16', 'utf-8-sig', 'utf-8', 'latin1', 'cp1252']:
            try:
                decoded_content = file_content_bytes.decode(encoding)
                break
            except UnicodeDecodeError:
                continue
        
        if decoded_content is None:
            st.error("N√£o foi poss√≠vel decodificar o arquivo. Tente salv√°-lo em UTF-8.")
        else:
            # Separamos el contenido en l√≠neas para procesar el encabezado
            lines = decoded_content.splitlines()
            if not lines:
                st.error("O arquivo est√° vazio.")
            else:
                # La primera l√≠nea contiene el encabezado. La segunda contiene los datos.
                header_line = lines[0]
                data_lines = lines[1:]
                
                # Leemos los datos a partir de la segunda l√≠nea, sin encabezado
                df_input = pd.read_csv(io.StringIO("\n".join(data_lines)), header=None, encoding=None, sep='\t')
                
                # Limpiamos el encabezado de BOMs y espacios y lo usamos para nombrar las columnas
                cleaned_header = [col.replace('\ufeff', '').strip() for col in header_line.split('\t')]
                df_input.columns = cleaned_header
                
                # Removemos la fila vac√≠a extra que a veces viene despu√©s del encabezado
                df_input.dropna(how='all', inplace=True)
                
                st.success("¬°Archivo cargado con √©xito!")
                st.info("Procesando los datos... por favor, espere.")
        
                df_reporte, resumen_final = processar_assistencia(df_input)
        
                if df_reporte is not None:
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("üë• Registros Totales", resumen_final['total_registros_processados'])
                    col2.metric("‚ùå Registros Ignorados", resumen_final['registros_ignorados'])
                    col3.metric("‚úÖ Estudiantes Presentes", resumen_final['presentes'])
                    col4.metric("üö´ Estudiantes Ausentes", resumen_final['ausentes'])
                    
                    st.divider()
                    st.header("üìä Reporte Final de Asistencia")
                    st.dataframe(df_reporte, use_container_width=True)
        
                    csv_buffer = io.StringIO()
                    df_reporte.to_csv(csv_buffer, index=False, encoding='utf-8')
                    csv_bytes = csv_buffer.getvalue().encode('utf-8')
        
                    st.download_button(
                        label="üì§ Descargar Reporte CSV",
                        data=csv_bytes,
                        file_name="reporte_asistencia_moodle.csv",
                        mime="text/csv",
                        help="Clique para baixar o arquivo CSV final."
                    )
                else:
                    st.warning("No se pudo generar el reporte. Verifique el formato de su archivo CSV.")

    except Exception as e:
        st.error(f"Ocurri√≥ un error inesperado: {e}")
        st.info("Aseg√∫rese de que el archivo es un CSV v√°lido de Webex y de que tiene todas las columnas requeridas.")

st.divider()
st.markdown("Creado con ‚ù§Ô∏è por el Agente Procesador de Asistencia.")
