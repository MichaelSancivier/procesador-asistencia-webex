import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import io
import re

# ====================================================================
# Funci√≥n de procesamiento del CSV de Webex
# ====================================================================
def processar_assistencia(df_input, duracao_fixa_min):
    """
    Processa um DataFrame de lista de presen√ßa do Webex e gera um relat√≥rio
    com base em uma dura√ß√£o de aula fixa.
    """
    df = df_input.copy()
    
    # Mapeamento de colunas esperadas
    colunas_esperadas = [
        'Nome da reuni√£o', 'Data de in√≠cio da reuni√£o', 'Data de t√©rmino da reuni√£o', 
        'Nome de exibi√ß√£o', 'Nome', 'Sobrenome', 'Fun√ß√£o', 'E-mail do convidado', 
        'Hora da entrada', 'Hora da sa√≠da', 'Dura√ß√£o da presen√ßa', 
        'Tipo de conex√£o', 'Nome da sess√£o'
    ]

    # Atribui√ß√£o e valida√ß√£o de colunas
    if len(df.columns) != len(colunas_esperadas):
        st.error(f"Erro: O n√∫mero de colunas lidas ({len(df.columns)}) n√£o corresponde ao esperado ({len(colunas_esperadas)}).")
        st.info("Isso pode indicar um formato de arquivo ou cabe√ßalho incorreto.")
        return None, None
        
    df.columns = colunas_esperadas
    
    st.info(f"Colunas do DataFrame (ap√≥s atribui√ß√£o manual): {list(df.columns)}")

    total_registros_processados = len(df)
    
    st.info(f"Total de registros lidos: {total_registros_processados}")
    
    registros_validos_antes = len(df)
    
    # 1. Remover registros com dados faltantes essenciais
    df.dropna(subset=['E-mail do convidado', 'Hora da entrada', 'Hora da sa√≠da'], inplace=True)
    registros_ignorados = registros_validos_antes - len(df)

    st.info(f"Registros restantes ap√≥s remover linhas com dados cruciais faltantes: {len(df)}")

    # 2. Limpar e converter colunas de tempo
    try:
        st.info("Tentando converter colunas de data/hora...")
        # REMOVER FORMATO DE F√ìRMULA DO EXCEL
        for col in ['Hora da entrada', 'Hora da sa√≠da', 'Data de in√≠cio da reuni√£o', 'Data de t√©rmino da reuni√£o']:
            df[col] = df[col].astype(str).str.replace('="', '', regex=False).str.replace('"', '', regex=False)
        
        df['Hora da entrada'] = pd.to_datetime(df['Hora da entrada'])
        df['Hora da sa√≠da'] = pd.to_datetime(df['Hora da sa√≠da'])
        df['Data de in√≠cio da reuni√£o'] = pd.to_datetime(df['Data de in√≠cio da reuni√£o'])
        df['Data de t√©rmino da reuni√£o'] = pd.to_datetime(df['Data de t√©rmino da reuni√£o'])
    except Exception as e:
        st.error(f"Erro ao converter colunas de data/hora. Verifique o formato dos dados. Erro: {e}")
        st.warning(f"Amostra de dados que causou o erro: {list(df['Hora da entrada'].head())}")
        return None, None

    if df.empty:
        st.warning("O DataFrame est√° vazio ap√≥s a limpeza dos dados.")
        return None, {"total_registros_processados": total_registros_processados, 
                      "registros_ignorados": registros_ignorados, 
                      "presentes": 0, "ausentes": 0}
    
    # GARANTIR QUE NOME/SOBRENOME SEJAM STRINGS
    df['Nome'] = df['Nome'].fillna('').astype(str)
    df['Sobrenome'] = df['Sobrenome'].fillna('').astype(str)

    # 3. Agrupar por e-mail para consolidar os registros
    grupos_por_email = df.groupby('E-mail do convidado')
    
    resultados = []
    
    # 4. Iterar sobre cada grupo (aluno)
    for email, grupo in grupos_por_email:
        entrada_consolidada = grupo['Hora da entrada'].min()
        saida_consolidada = grupo['Hora da sa√≠da'].max()
        
        # --- CORRE√á√ÉO: CALCULAR TEMPO TOTAL COM BASE NO HOR√ÅRIO CONSOLIDADO ---
        tempo_total_min = (saida_consolidada - entrada_consolidada).total_seconds() / 60
        
        # --- C√ÅLCULO FINAL: USAR DURA√á√ÉO FIXA ---
        porcentagem_tempo = (tempo_total_min / duracao_fixa_min) * 100
        
        status = 'P' if porcentagem_tempo >= 80 else 'FI'
        
        nome_aluno = str(grupo.iloc[0]['Nome']) + ' ' + str(grupo.iloc[0]['Sobrenome'])
            
        resultados.append({
            'Nome': nome_aluno,
            'E-mail do convidado': email,
            'Entrada Consolidada': entrada_consolidada.strftime('%Y-%m-%d %H:%M:%S'),
            'Sa√≠da Consolidada': saida_consolidada.strftime('%Y-%m-%d %H:%M:%S'),
            'Tempo Total (min)': round(tempo_total_min, 2),
            'Porcentagem de Tempo (%)': round(porcentagem_tempo, 2),
            'Status': status
        })

    # 5. Gerar o novo DataFrame
    df_final = pd.DataFrame(resultados)
    
    # 6. Gerar o resumo
    presentes = len(df_final[df_final['Status'] == 'P'])
    ausentes = len(df_final[df_final['Status'] == 'FI'])
    
    resumo = {
        "total_registros_processados": total_registros_processados,
        "registros_ignorados": registros_ignorados,
        "presentes": presentes,
        "ausentes": ausentes
    }
    
    return df_final, resumo

# ====================================================================
# Interfaz de usuario con Streamlit
# ====================================================================

st.set_page_config(page_title="Procesador de Asistencia Webex", layout="wide", page_icon="üë®‚Äçüè´")
st.title("üë®‚Äçüè´ Procesador de Asistencia para Moodle")
st.markdown("Suba su archivo CSV de la lista de presencia de Webex para generar un informe listo para importar en Moodle.")
st.divider()

# --- NOVO CAMPO DE ENTRADA PARA A DURA√á√ÉO FIXA ---
duracao_fixa = st.number_input(
    "üìè **Dura√ß√£o Total da Aula (em minutos):**",
    min_value=1,
    value=240,
    help="Insira a dura√ß√£o planejada da aula para calcular a porcentagem de tempo. Padr√£o: 240 min (4 horas)."
)
st.divider()
# --------------------------------------------------

uploaded_file = st.file_uploader("üì• Cargue el archivo CSV aqu√≠", type=["csv"])

if uploaded_file is not None:
    try:
        df_input = None
        read_configs = [
            {'encoding': 'utf-16', 'sep': '\t', 'header': 0},
            {'encoding': 'utf-8-sig', 'sep': '\t', 'header': 0}, 
            {'encoding': 'latin1', 'sep': '\t', 'header': 0},
            {'encoding': 'utf-8', 'sep': '\t', 'header': 0},
            {'encoding': 'utf-8', 'delim_whitespace': True, 'header': 0},
            {'encoding': 'latin1', 'delim_whitespace': True, 'header': 0},
            {'encoding': 'utf-8', 'sep': ',', 'header': 0},
            {'encoding': 'latin1', 'sep': ',', 'header': 0},
            {'encoding': 'utf-8', 'sep': ';', 'header': 0},
            {'encoding': 'latin1', 'sep': ';', 'header': 0},
        ]
        
        for config in read_configs:
            try:
                uploaded_file.seek(0)
                df_input = pd.read_csv(uploaded_file, **config)
                if not df_input.empty and len(df_input.columns) > 1:
                    st.info(f"Arquivo lido com sucesso! Delimitador: '{config.get('sep', 'whitespace')}', Codifica√ß√£o: '{config['encoding']}'.")
                    break  
            except (UnicodeDecodeError, pd.errors.ParserError):
                continue
            except Exception:
                continue

        if df_input is None or df_input is None or len(df_input.columns) <= 1:
            st.error("Erro ao ler o arquivo. N√£o foi poss√≠vel determinar a codifica√ß√£o ou o delimitador correto. Tente salvar o CSV como UTF-8 com v√≠rgulas ou tabula√ß√µes como delimitador.")
        
        else:
            st.success("¬°Archivo cargado con √©xito!")
            st.info("Procesando los datos... por favor, espere.")
    
            df_reporte, resumen_final = processar_assistencia(df_input, duracao_fixa)
    
            if df_reporte is not None:
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("üë• Registros Totales", resumen_final['total_registros_processados'])
                col2.metric("‚ùå Registros Ignorados", resumen_final['registros_ignorados'])
                col3.metric("‚úÖ Estudiantes Presentes", resumen_final['presentes'])
                col4.metric("üö´ Estudiantes Ausentes", resumen_final['ausentes'])
                
                st.divider()
                st.header("üìä Reporte Final de Asistencia")
                st.dataframe(df_reporte, use_container_width=True)
    
                csv_buffer = io.StringIO()
                df_reporte.to_csv(csv_buffer, index=False, encoding='utf-8')
                csv_bytes = csv_buffer.getvalue().encode('utf-8')
    
                st.download_button(
                    label="üì§ Descargar Reporte CSV",
                    data=csv_bytes,
                    file_name="reporte_asistencia_moodle.csv",
                    mime="text/csv",
                    help="Clique para baixar o arquivo CSV final."
                )
            else:
                st.warning("No se pudo generar el reporte. Verifique el formato de su archivo CSV.")

    except Exception as e:
        st.error(f"Ocurri√≥ un error inesperado: {e}")
        st.info("Aseg√∫rese de que el archivo es un CSV v√°lido de Webex y de que tiene todas las columnas requeridas.")

st.divider()
st.markdown("Creado con ‚ù§Ô∏è por el Agente Procesador de Asistencia.")
